Title: 
Control and conformance through obligatory passage points


Abstract:
15 years ago a group of sociologists looked at successful open source projects and wondered what could be _read off_ the 

A central consideration in managing a successful technical project is to ensure the consistency and quality of the technological artifact under 

production. A means to achieve this, is to look at common problems through the lens of Actor—Network theory (ANT), 

Committed abstract:

15  years  ago  a  group  of  sociologists  looked  at  successful  open  source  projects
and wondered what could be
read off
the source code.  Though the rhetoric of
these  open  source  projects  were  about  openness  and  access,  the  source  codes
told stories about closedness and regulation.
In my talk, I look at the group’s discussion of the
obligatory passage point
, and
how  it  may  produce  control  and  conformance  of  socio-technical  norms  in  our
own technical projects

A socio-technical organization must be made in order to give rise to a structure that vets both developer and the code which is produced. This talk concerns the technical elements of this structure, and the extent to which they can become obligatory passage points—a narrowing of the structure that the developer must navigate in order to produce. I show what these elements are, and how they are used.

Outline:
- Some design decisions for some patterns are hard to make
- In successful open source projects, these patterns emerged
-  

"wildly irresponsible it is, to have allowed it to go so far out of your control, that you don't know what it's going to do when you change a line of code"

-------------
Imagine that you are tasked with fixing a bug inside some API. It requires you to change a piece of code that has rotted. And by rotted I mean that nobody has done anything to make the code better in a long time. And every time someone changed it, they did the least amount of edits that they had to. The code has no tests, and you're certain that changing it, will break something over _here_. And I think this is a quite common problem for a lot of software development projects.

Uncle Bob Martin, the famous software craftsman, he describes this, and says that: "to have allowed this code to go so far beyond your control, that you don't know what it's going to do when you change it, is _wildly_ irresponsible".

So, how do you take back control? We refactor and add tests. This is an essential part of being a software craftsperson. But in some cases, refactoring and tests aren't enough. What if the reason for the code's rot, is that the API is being used in ways that you never originally intended? (And I mean in a bad way.) Maybe the API leaked too much abstraction? Or that it was simply at the wrong level of abstraction from the start. To fix this, you cannot simply move a couple of methods, or split some classes. In these cases, the API has to fundamentally change.

Any software craftsman or craftswoman should constantly improve their creations. This is part of the programmer's oath. In this case it means API breakage, or deprecation. Or a completely new API.

Now, what is the underlying reason for why you being reluctant to change the code in this API? One way of thinking about this, is to view it as a lack of control and conformance. In the case of an API at a too low abstraction level, you have no control over how these low level abstractions are used together.

If you have rules and requirements, or norms, for the use of this API, and there is nothing in the API that produces conformance — any conformance must be assured through social contract. Maybe you've told your users that "no don't use the API in this way, that will slow the database down" or "please use these methods only on these data" and so on. This is futile in the long run, and more the code will rot even further.

A major shift of control away from the API users has to take place. In your case, with the wrong abstraction level, you need to export code at a higher abstraction level. This means less concrete classes and methods, maybe entirely new concepts and datas.

With this major shift of control from the user to you, the user can no longer do "everything", but perhaps just the required things. The API user also has to conform to your new norms. For example, since you were worried the user would crash the database with inefficient queries, you have now written all the queries for them. They can no longer simply write their own queries. You no longer have to go to their desks and tell them anything. They conform simply by using your API.

This way, your code's integrity can be protected across changes in the implementation. You might change the database system, you might drastically change the underlying data structure, and so on. These points of variation are predictable in our line of work. This is the principle of _variation behind interface_. It is the superclass of a lot of programming patterns.

But is this enough to justify this major shift of control? Can you justify API breakage on this principle alone? You might face some resistance. The API users might view this change as a waste of their time. Because they currently use your API, and they probably have no problems with it. Sure, it's difficult at times finding the correct buttons to push to make anything work, but it works—right now! And it is flexible. They can do whatever they want. Now you want to reduce their power and freedom for the sake of this principle? 

Luckily, there might be another way to justify the need for production of control and conformance of these socio-technical norms.

This other way, is an idea taken from a 20 year old sociology paper. A group of sociologists looked at successful open source software projects, one of them Python. And asked: what can we tell about the way these open source developers work, by simply looking at the code?

And they found that, even though the narrative of these projects usually was about openness and access—the code was nothing but closedness and regulation. For example, since they had no way of producing conformance through social contract, they did not rely on it at all. They built in conformance of their rules and requirements into the code.

And this was not just at the technical level—the source code controlled and constrained their development processes too. The source code partitioned and managed activities by the use of components, modules. It also limited access to parts of code using higher order concepts like plugins, publish/subscribe patterns, domain specific languages, and so on.

And the group found that these structures were emergent. Meaning that the structures were not formally defined, or deliberately created in these projects. This is interesting in light of the open source movement's focus on participation and accessibility.

They structures were seemingly just a necessity in order to be successful.

And trying to understand how this dynamic, they turned to Actor-Network theory (ANT). So, first, what roughly is ANT?

ANT can be summarized as follows:

1) In ANT, _everything_ in the area of interest, in this case, a software development project, is in the network. Nothing exists outside the network. So this is not a clean graph that we might know from computer science. It is a fibrous, messy thing.
2) ANT insists that humans, as well as non-humans, for example, code modules, deployment processes, etc, can be actors in the network. Looking through the lens of ANT, a code module and a developer can have play the same part.

So looking at for example the Python source code, through the lens of ANT, the sociologists found a bunch of what they called _obligatory passage points_ (OPP). OPP are narrowings of the network that some actor has to go through in order to achieve a result. 

To the sociologists, this was the exact same way that scientific progress was made. They suggest that the social processes that shape scientific practice, are the creation of these networks that includes these obligatory passage points. Examples of these obligatory passage points could be: scientific journals, sensitive lab equipment, experimental verification, and solid theoretical foundations. These obligatory passage points stabilize scientific results, and establishes the reliability of observations, results and conclusions.

Back to your API. How can you use the obligatory passage point to justify the rewrite of this API?




------------------
An example of how this theory works, is the fact that functions embedded in social settings may be delegated to technology. For instance, rather than have a policeman monitor road traffic to ensure conformance with speed limits, we can lay down “speed bumps” to achieve the same effect. And in the UK, speed bumps are even sometimes called sleeping policemen. Technological arrangements, as much as social arrangements, can be used to produce control and conformance with social norms.

For you to get from here to there on the road, and there's a speed bump in the way, you need to pass over it. So you slow down, and conform to the speed limits. So the speed bump _is_ an Obligatory Passage Point.

If there's a road on which you can drive around the speed bump, conformance of speed limits goes away. Similarly, if your API is poorly designed, it is going to be misused.

One explanation then, for why you did not dare touch the code, and why refactoring simply would not be enough, is that the network was too broad. There were too many passage points. It offered too little control over how it was being used, and there was little or no conformance of the few rules that might have existed in the API.

Say we then, design a new API, that offers a great deal of control over how the underlying mechanism are being used, and that forces the consumer to conform to your idea of how it should be used. This would be the narrowing of the network, and then become a obligatory passage point.

What is the virtue of the OPP, or of control and conformance? To answer this, the sociologists turn to the scientific process. They say that part of successful scientific process, is the construction of networks that help stabilize results. Sensitive laboratory equipment, experimental verification, and solid theoretical foundations become actors in these networks, they all act as obligatory passage points.






-------------

An example is if you export a data base connection and the code that works on the data returned by some special data query. If it is left to the user to query the database, and how to correctly use the data returned. You have no means of controlling that it is done correctly. Similarly, if the database is slow, and you require your users to conform to the rule that database queries needs to be fast and small—how can you ensure conformity other than via social contract?


--------------
Let us travel back in time, 20 years. Imagine you are responsible for introducing continuous integration in your organization. Almost nobody knows what it is. And integration currently takes a long time, weeks maybe months. You're now telling the organization that it should integrate multiple times a day using automated jobs. Oh and to add unit test and that they should pass with each integration. So you introduce this norm into the organization: "development branches should integrate frequently with a shared state, cleanly, with unit tests passing." And then you create a CI system that controls integration and forces everyone to conform. 

This is is a shift of control away from the individual development teams, to the CI system. And conformance of the norm is now required to integrate—in essence, to do any actual software development.

The CI system is an example of the Obligatory Passage Point. 


Back to the present. We now know CI is integral to making integration a non-event. During the interview to get the job you are asked about CI. So this [the norm] is a good, socio-technical norm, and a CI produces control and conformance of it. 

We, as software craftsmen and craftswomen, make small shifts in control all the time. It might not always be shifts in the control held by people, but rather code. Imagine doing refactoring, and you see that two objects A and B know too much about each other. Fixing this requires to have A be more knowledgble 



-------------
Imagine that you are the author of a library to be used by some other development team in your organization. The purpose of the library is to provide an API to allow manipulation of—let's say— a cloud service on which your organization depends. You think that it is a good idea to allow the cloud service provider to vary—even though your library, from the perspective of the other team, does not.

There are many ways to do this, let's say you create an a Doman-Specific Language (DSL). This will impose measures of control and conformance on the other development team, both socially and technically:

To use or change this library, they have to communicate with you, and to actually use the cloud provider service, they need to call your code. So they have to accept these terms, as well as the way the DSL is designed.

This is not trivial to do. Why? Because first you must convince yourself and your team that this is the right thing to do. And then you have to convince the other team, that this is the right way to go. And then you have to actually implement the thing, so that it works as promised. The other team is waiting, the whole organization is waiting on this library.

So, how do we justify imposing control and conformance on each other, when there might be a quicker and easier way to do it—without the introduction of any such measures? In other words, I could just create a 1000 lines python script that did the trick. This is the problem I want to talk about.

I will talk about n arguments for taking the more closed and regulated route:

0. The Obligatory Passage Point

15 years ago, sociologists took a bunch of successful open source projects, and looked closely at the source code of each project. Though the narrative of these projects were about openness and access for the contributing developers, the actual code was all about closedness and regulation. The sociologists weren't surprised, because they had seen it many times before. 

1. The programmers fifth oath
 -- I will fearlessly and relentlessly improve my creations at every opportunity. I will never degrade them.
 
So what would happen if you took the quick and easy approach to library development, and created code that had leaky abstractions, and you organization then changes the cloud service provider? The library degrades. Fear of imposing too much hassle on the other team now made the entire library useless to them.

You should never fear protecting your code against predictable points of variation.

2. It is uncontroversial to impose control and conformance on each other














-----------
15 years ago, a group of sociologists looked at successful, open source software projects, and wondered what they could find if they dug deep into the source code. They found that though the narrative of such open source projects may be about openness and access, the practice in the source code of these projects, is about closedness; control and conformance.



I want to talk about how hard it might be, as software craftsmen and women, to introduce measures of control and conformance on each other. And I want to talk about an interesting idea from sociology that might make it easier.

By socio-technical norms I mean the rules and requirements that we apply to the social and technical aspects of software development. Take for instance, the rule that "our code should cleanly integrate". The organization make teams conform to this, by requiring some continuous integration job to successfully run on our branch of code, before it is integrated into the mainline. 

As craftsmen and craftswomen, we should try to fearlessly and relentlessly improve our creations. Sometimes, however, this means imposing measures of control and conformance on each other. And some software developers (myself included) hate rules!

So control and conformance is not trivial to introduce. Because not only must you convince yourself about the necessity of the measure you are introducing, but you need to be able to convince everybody else—and this is on top of the actual work of implementing the measure itself! For me, this is daunting. It is risky. What if I am wrong? Did I waste everyone's time?

On the other hand, little or no control or conformance is an absolute nightmare. How terrifying and wildly irresponsible is it, to have allowed your code to go so far out of your control, that you don't know what it's going to do when you change a line of code?

So, to make this easier, I will present a concept from sociology called the Obligatory Passage Point.


And by socio-technical norms I mean the rules and requirements that apply to both the social and technical aspects of software development. And these norms are essential to our craft. And as we shall see, it may be empirically provable to be vital to the success of any technical project.

But imposing control and conformance on other software craftspersons may be challanging, even with empirical evidence proving the necessity of the measure. I think this is natural—software developers hate rules!





So, examples of these means of control norms are plenty, we know them from our own technical projects in SIB:
- kanban and issue tracker (though I think Kristian may be about to change that)
- continous integration, we want developers to conform to a set of requirements: that code integrates cleanly, tests should pass, etc.
- source control management: code is controlled by use of git, and no software can (practically) be deployed without it
- unit tests, good software design, etc, etc.

However, I want to focus on measures that directly control the dependency between authors of code. Examples of these measures are also well known to us, and extensively used:
- APIs,
- interfaces,
- facades,
- modularization,
and so on.

Some means in this category, less used by us (or at least me) to control the other developers e.g. in the same team. However, these are extensively used by developers of software that we use and depend on:
- plug-in systems, we immediately think of more mainstream software like Firefox, <your favorite editor> plugins, event loop APIs
- event loops/PUB-SUB-type patterns, we may have used these when using Qt, boost signals, etc  
- domain specific languages (DSL)
- Model-View-Controller
- etc

---

Now, when to use these latter means of control and conformance, has been a major struggle for me. Because they do impose all kinds of inconvenience for the consumer—at first—but will eventually, maybe, provide value.



We all want to become better developers. And for me, for as long as I have been working with software development, a major struggle has been: when should I or must I introduce measures of control and conformance, of:
    - internal developers
    - external developers

By control, I mean that for example I develop a module and for you to use that module, you have to call this particular method. Conformance means you use this particular method as expected. 

This level of control and conformance is easy to justify. I create an interface which you must use, so that my implementation can vary without it affecting you. This is universially accepted by most software craftspersons. So are others:
    - basic software design, use the units of the programming language (classes, functions, variables) to create good code 
    - TDD: all code must be tested
    - continuous integration, we force developers to make sure their code integrates according to some set of requirements (no conflicts, tests pass, etc)
    - use an issue tracker, all things causing a change in the software artifact (i.e. running program, deployment, source code, etc), must be triggered by some issue

 Higher-order means of control, however, may be harder to introduce. For example, the plugin system. The plugin system means at least two layers of interfaces for the consumer. The plugin system has one interface, and the underlying interfaces that the plugin system itself uses. 




has been when to introduce code with a structure that resembles plugins, extensible component-based systems, or similar styles. How can I justify forcing you, either an internal or external developer, or a power user, to conform to, and be controlled by my code?

We all want to become better craftspersons. For me, one of the major recurring problems, has been the use of higher order design patterns.

  


What is OPP:
Discuss what it is, and the ANT details that make it interesting.

How can it be applied to code:
Mainly three ways: API, Plugins, Protocol

Why
- logic argument first
- then the descriptive part from software archeology


Talk:
15 years ago, a group of sociologists looked at successful open source software projects that were accessible and cherished openness, and asked the following question: if you look at the source code over time, [finn ut hva spørsmålet er]. The answer was clear cut yes—there was ample evidence of rigidity and closedness. And we know one of the projects very well, here in SIB—python.




So, in my talk i want to [discuss obligatory passage] points. We all intuitively know what these are—they are hoops [show dog jumping through hoop]. Hoops we developers, stakeholders, et. al., needs to jump through in order to get something done.

We have many examples of these hoops in our day-to-day lives when creating software. Code review, issue tracking, product owner (unless you are one), developers (unless you are the only one), etc. More technical ones are source control management, continuous integration (CI), the compiler/interpreter, even programming units like variables, methods, classes, etc. We rarely think about these in terms of what they really are—or at least I don't; they are ways in which we apply control to our artifact, and make various stages in the projects life cycle conform to some set of requirements.

In Actor–network theory (ANT), all these hoops would be known as Obligatory Passage Points. Looking at a software development through the lens of ANT, everything from the artifact under production, to the customer itself, is an actor. And there is nothing comprising the network, … clarify?

Examples of these are social ones, like code review and issues tracking [github screenshots?]. It could also be people—some person you need to talk to in order to do something. Other examples, from the technical realm, are unit testing, CI, proper use of software units—classes, modules, packages, or the use of design patterns, etc. And you code will have to conform to the constraints of syntax and be version controlled.


The term obligatory passage point is lent from [Actor-Network Theory (ANT)]. When reasoning about e.g. a software development project in ANT, there's a couple of points that are important:
 - [The network is all there is]. (sett inn det fra de Souza)
 - [Anything can and must be an actor] (sett inn fra de Souza)
 - konklusjon fra de Souza?

So, with this in mind, how often do we consider the code to be an instrument of control and conformance?
